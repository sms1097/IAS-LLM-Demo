{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leveraging an LLM for Customer Experience Tracking\n",
    "\n",
    "\n",
    "### Problem Statement\n",
    "\n",
    "One Travel is facing a significant challenge quantitatively measuring customer feedback, especially when trying to capture subjective sentiments expressed in customer reviews. The need to answer specific questions, such as the performance of a new boarding process, changes in seating, and other common airline related changes.\n",
    "\n",
    "They don't want to use surveys. Surveys are known to create different types of biases, and when large organizations like airlines have multiple policy changes it can be hard to capture all relevant feedback in one survey, leading to low completion rates. Surveys also don't allow you to go back and track different concepts as they change over time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An Innovative Solution\n",
    "One Travel instead opts to use a Large Language Model (LLM) to track their feedback and the relevant categories. Instead of using a survey and asking a question for the customer to respond to, they instead ask the customer to write about their trip and explain what is top of mind. They then use the LLM to determine if the customer menitoned their category they are tracking and record what the customer experience was. Let's walk through what this approach could look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/seansmith/anaconda3/envs/airline/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tiktoken\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from openai import OpenAI\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import seaborn as sns\n",
    "from tenacity import retry, stop_after_attempt, wait_fixed\n",
    "from huggingface_hub import InferenceClient\n",
    "\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\".env\")\n",
    "\n",
    "openai_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "HF_TOKEN = os.environ[\"HF_TOKEN\"]\n",
    "TOGETHER_API_KEY = os.environ[\"TOGETHER_API_KEY\"]\n",
    "\n",
    "\n",
    "GPT3 = \"gpt-3.5-turbo-1106\"\n",
    "GPT4 = \"gpt-4-1106-preview\"\n",
    "ZEPHYR = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "\n",
    "\n",
    "def num_tokens_from_string(string: str) -> int:\n",
    "    encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n",
    "\n",
    "\n",
    "@retry(wait=wait_fixed(15), stop=stop_after_attempt(4))\n",
    "def llm(user_prompt, model, temperature=0.3):\n",
    "    model_kwargs = {\"temperature\": temperature}\n",
    "    user_prompt = user_prompt[:3700]\n",
    "\n",
    "    client = OpenAI(api_key=OPENAI_KEY)\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": user_prompt}],\n",
    "        stream=False,\n",
    "        **model_kwargs,\n",
    "    )\n",
    "\n",
    "    output = response.choices[0].message.content\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLIENT = OpenAI(\n",
    "    api_key=TOGETHER_API_KEY,\n",
    "    base_url=\"https://api.together.xyz\",\n",
    ")\n",
    "\n",
    "\n",
    "def llm(user_prompt, model=\"mixtral\", temperature=0.1):\n",
    "    model_kwargs = {\"temperature\": temperature}\n",
    "    user_prompt = user_prompt[:3700]\n",
    "\n",
    "    chat_completion = CLIENT.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": user_prompt\n",
    "            },\n",
    "        ],\n",
    "        model=\"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n",
    "        # model=\"NousResearch/Nous-Hermes-2-Mixtral-8x7B-SFT\",\n",
    "        # model='mistralai/Mistral-7B-Instruct-v0.2',\n",
    "        **model_kwargs\n",
    "    )\n",
    "    output = chat_completion.choices[0].message.content\n",
    "    return output "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Choose Categories\n",
    "The business stakeholders choose the categories they would like to track. This can be any arbitrarily changed and augmented as time goes one, making this solution very flexible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [\n",
    "    \"seat_comfort\",\n",
    "    \"cabin_staff_service\",\n",
    "    \"food_and_beverages\",\n",
    "    \"inflight_entertainment\",\n",
    "    \"ground_service\",\n",
    "    \"wifi_and_connectivity\",\n",
    "    \"value_for_money\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load in Some Comments\n",
    "Next we load in reviews from some airline passengers. This data can come from wherever your organization stores its data. In this case we just load from a file that we have on hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>category</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1326</th>\n",
       "      <td>✅ Trip Verified |  San Francisco to Reno. This...</td>\n",
       "      <td>food_and_beverages</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1041</th>\n",
       "      <td>Phoenix to Boston via Houston with United Airl...</td>\n",
       "      <td>food_and_beverages</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3194</th>\n",
       "      <td>Not Verified |  50 min to check luggage. Long ...</td>\n",
       "      <td>wifi_and_connectivity</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>✅ Trip Verified | The worst thing that can hap...</td>\n",
       "      <td>seat_comfort</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Not Verified |  My husband and I paid for a pr...</td>\n",
       "      <td>seat_comfort</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 review  \\\n",
       "1326  ✅ Trip Verified |  San Francisco to Reno. This...   \n",
       "1041  Phoenix to Boston via Houston with United Airl...   \n",
       "3194  Not Verified |  50 min to check luggage. Long ...   \n",
       "361   ✅ Trip Verified | The worst thing that can hap...   \n",
       "0     Not Verified |  My husband and I paid for a pr...   \n",
       "\n",
       "                   category sentiment  \n",
       "1326     food_and_beverages   Neutral  \n",
       "1041     food_and_beverages  Negative  \n",
       "3194  wifi_and_connectivity   Neutral  \n",
       "361            seat_comfort  Negative  \n",
       "0              seat_comfort  Negative  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs[['review', 'category', 'sentiment']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Tag the Comments\n",
    "Now that we have the reviews loaded we can ask the LLM to review the information. Here's what that looks like. Notice the advantage that we can handle this problem with plain text. With a small amount of training, any non-technical stakeholder could easily extend this system to handle slightly different tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_prompt_template = lambda review: f\"\"\"\n",
    "Here's a customer review for an experience they had on an airline.\n",
    "For each of the following categories decide if the customer's sentiment is Positive, Negative, or Neutral.\n",
    "If a category is not mentioned return \"N/A\".\n",
    "The intended airline is Untied Airlines.\n",
    "\n",
    "Return using ONLY the following output schema.\n",
    "- seat_comfort: <sentiment>\n",
    "- cabin_staff_service: <sentiment>\n",
    "- food_and_beverages: <sentiment>\n",
    "- inflight_entertainment: <sentiment>\n",
    "- ground_service: <sentiment>\n",
    "- wifi_and_connectivity: <sentiment>\n",
    "- value_for_money: <sentiment>\n",
    "- Is the airline reccomended: <True/False>\n",
    "\n",
    "Return only in the above format.\n",
    "\n",
    "Review: {review}\n",
    "Output: \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_output(llm_output, categories):\n",
    "    output = {}\n",
    "    category_reviews = [x.lstrip(\"- \") for x in llm_output.split(\"\\n\")]\n",
    "    for category_name, review in zip(categories, category_reviews):\n",
    "        # format the information\n",
    "        rating=review.replace(f\"{category_name}: \", '').split('(')[0]\n",
    "        output[f\"{category_name} pred\"] = rating\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'seat_comfort pred': 'N/A',\n",
       " 'cabin_staff_service pred': 'Negative',\n",
       " 'food_and_beverages pred': 'N/A',\n",
       " 'inflight_entertainment pred': 'N/A',\n",
       " 'ground_service pred': 'Negative',\n",
       " 'wifi_and_connectivity pred': 'N/A',\n",
       " 'value_for_money pred': 'N/A'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = df.review.sample(1).iloc[0]\n",
    "prompt = tag_prompt_template(tmp)\n",
    "output = llm(prompt)\n",
    "parse_output(output, categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Report on Changes in Comments\n",
    "\n",
    "This is a really good use case for Prediction-Powered Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import brentq\n",
    "from scipy.stats import binom, norm\n",
    "\n",
    "\n",
    "def binomial_iid(N, alpha, muhat):\n",
    "    def invert_upper_tail(mu):\n",
    "        return binom.cdf(N * muhat, N, mu) - (alpha / 2)\n",
    "\n",
    "    def invert_lower_tail(mu):\n",
    "        return binom.cdf(N * muhat, N, mu) - (1 - alpha / 2)\n",
    "\n",
    "    u = brentq(invert_upper_tail, 0, 1)\n",
    "    l = brentq(invert_lower_tail, 0, 1)\n",
    "    return np.array([l, u])\n",
    "\n",
    "\n",
    "def pp_mean_iid_asymptotic(Y_labeled, Yhat_labeled, Yhat_unlabeled, alpha):\n",
    "    n = Y_labeled.shape[0]\n",
    "    N = Yhat_unlabeled.shape[0]\n",
    "    tildethetaf = Yhat_unlabeled.mean()\n",
    "    rechat = (Yhat_labeled - Y_labeled).mean()\n",
    "    thetahatPP = tildethetaf - rechat\n",
    "    sigmaftilde = np.std(Yhat_unlabeled)\n",
    "    sigmarec = np.std(Yhat_labeled - Y_labeled)\n",
    "    hw = norm.ppf(1 - alpha / 2) * np.sqrt((sigmaftilde**2 / N) + (sigmarec**2 / n))\n",
    "    return [thetahatPP - hw, thetahatPP + hw]\n",
    "\n",
    "\n",
    "def calculate_ppi(Y_labeled, Yhat_labeled, Yhat_unlabeled, alpha, num_trials=100):\n",
    "    # Imputed-only estimate\n",
    "\n",
    "    n_max = Y_labeled.shape[0]  # Total number of labeled ballots\n",
    "    ns = np.linspace(1, n_max, 20).astype(int)\n",
    "\n",
    "    imputed_estimate = (Yhat_labeled.sum() + Yhat_unlabeled.sum()) / (\n",
    "        Yhat_labeled.shape[0] + Yhat_unlabeled.shape[0]\n",
    "    )\n",
    "\n",
    "    # Run prediction-powered inference and classical inference for many values of n\n",
    "    ci = np.zeros((num_trials, ns.shape[0], 2))\n",
    "    ci_classical = np.zeros((num_trials, ns.shape[0], 2))\n",
    "\n",
    "    for i in tqdm(range(ns.shape[0])):\n",
    "        for j in range(num_trials):\n",
    "            # Prediction-Powered Inference\n",
    "            n = ns[i]\n",
    "            rand_idx = np.random.permutation(n)\n",
    "            f = Yhat_labeled.astype(float)[rand_idx[:n]]\n",
    "            y = Y_labeled.astype(float)[rand_idx[:n]]\n",
    "\n",
    "            ci[j, i, :] = pp_mean_iid_asymptotic(y, f, Yhat_unlabeled, alpha)\n",
    "\n",
    "            # Classical interval\n",
    "            ci_classical[j, i, :] = binomial_iid(n, alpha, y.mean())\n",
    "\n",
    "    avg_ci = ci.mean(axis=0)[-1]\n",
    "    avg_ci_classical = ci_classical.mean(axis=0)[-1]\n",
    "\n",
    "    return {\"ppi\": avg_ci, \"classical\": avg_ci_classical, \"imputed\": imputed_estimate}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3h/n02_9ld51cl6fd_hblg7_3500000gn/T/ipykernel_70097/2263965139.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  category_df['sentiment'] = category_df.sentiment.map({'Positive': 1, 'Negative': 0})\n",
      "/var/folders/3h/n02_9ld51cl6fd_hblg7_3500000gn/T/ipykernel_70097/2263965139.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  category_df[model] = category_df[model].map({'Positive': 1, 'Negative': 0})\n"
     ]
    }
   ],
   "source": [
    "c = categories[1]\n",
    "model = \"mistralai/Mixtral-8x7B-Instruct-v0.1_pred\"\n",
    "category_df = df[(df.category == c) ]\n",
    "category_df['sentiment'] = category_df.sentiment.map({'Positive': 1, 'Negative': 0})\n",
    "category_df[model] = category_df[model].map({'Positive': 1, 'Negative': 0})\n",
    "category_df = category_df[~category_df[model].isna()]\n",
    "category_df = category_df[~category_df.sentiment.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed = category_df.sample(n=100)\n",
    "y_labeled = observed[\"sentiment\"].to_numpy()\n",
    "yhat_labeled = observed[model].to_numpy()\n",
    "# yhat_unlabeled = category_df[~category_df.index.isin(observed.index)][model].to_numpy()\n",
    "yhat_unlabeled = category_df.sample(n=1000, replace=True)[model].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:19<00:00,  1.04it/s]\n"
     ]
    }
   ],
   "source": [
    "confidence_intervals = calculate_ppi(\n",
    "    y_labeled, yhat_labeled, yhat_unlabeled, 0.05, num_trials=1000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ppi': array([0.24761803, 0.40238197]),\n",
       " 'classical': array([0.23919853, 0.42076686]),\n",
       " 'imputed': 0.26454545454545453}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confidence_intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick Accuracy Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_category_accuracies(model):\n",
    "    for category_name in categories:\n",
    "        tmp_df = df[\n",
    "            (~df[model].isna())\n",
    "            & (~df['sentiment'].isna())\n",
    "            & (df[\"category\"] == category_name)\n",
    "        ]\n",
    "        acc = tmp_df[tmp_df[model] == tmp_df['sentiment']].shape[0] / tmp_df.shape[0]\n",
    "        print(f'{category_name} Accuracy: {round(acc,4)}  (n={tmp_df.shape[0]})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seat_comfort Accuracy: 0.62  (n=150)\n",
      "cabin_staff_service Accuracy: 0.7273  (n=396)\n",
      "food_and_beverages Accuracy: 0.6818  (n=154)\n",
      "inflight_entertainment Accuracy: 0.6796  (n=103)\n",
      "ground_service Accuracy: 0.7208  (n=394)\n",
      "wifi_and_connectivity Accuracy: 0.4643  (n=56)\n",
      "value_for_money Accuracy: 0.8792  (n=389)\n"
     ]
    }
   ],
   "source": [
    "model = \"mistralai/Mixtral-8x7B-Instruct-v0.1_pred\"\n",
    "score_category_accuracies(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seat_comfort Accuracy: 0.8447  (n=309)\n",
      "cabin_staff_service Accuracy: 0.8223  (n=484)\n",
      "food_and_beverages Accuracy: 0.7533  (n=150)\n",
      "inflight_entertainment Accuracy: 0.7812  (n=96)\n",
      "ground_service Accuracy: 0.7809  (n=429)\n",
      "wifi_and_connectivity Accuracy: 0.7222  (n=36)\n",
      "value_for_money Accuracy: 0.9071  (n=366)\n"
     ]
    }
   ],
   "source": [
    "model = \"gpt-3.5-turbo-1106_pred\"\n",
    "score_category_accuracies(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seat_comfort Accuracy: 0.7736  (n=212)\n",
      "cabin_staff_service Accuracy: 0.8245  (n=416)\n",
      "food_and_beverages Accuracy: 0.7534  (n=146)\n",
      "inflight_entertainment Accuracy: 0.8172  (n=93)\n",
      "ground_service Accuracy: 0.788  (n=401)\n",
      "wifi_and_connectivity Accuracy: 0.7179  (n=39)\n",
      "value_for_money Accuracy: 0.9106  (n=425)\n"
     ]
    }
   ],
   "source": [
    "model = \"gpt-4-1106-preview_pred\"\n",
    "score_category_accuracies(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seat_comfort Accuracy: 0.798  (n=500)\n",
      "cabin_staff_service Accuracy: 0.718  (n=500)\n",
      "food_and_beverages Accuracy: 0.6124  (n=498)\n",
      "inflight_entertainment Accuracy: 0.501  (n=497)\n",
      "ground_service Accuracy: 0.674  (n=497)\n",
      "wifi_and_connectivity Accuracy: 0.497  (n=497)\n",
      "value_for_money Accuracy: 0.841  (n=497)\n"
     ]
    }
   ],
   "source": [
    "model = 'small_model_predictions'\n",
    "score_category_accuracies(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Flexibly Change the Output Classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_prompt_template = lambda review: f\"\"\"Here's a customer review for an experience they had on an airline.\n",
    "For each of the following categories decide if the customer's sentiment is Positive, Negative, or Neutral.\n",
    "If a category is not mentioned return \"N/A\".\n",
    "The intended airline is Untied Airlines.\n",
    "\n",
    "Return using ONLY the following output schema.\n",
    "- seat_comfort: <sentiment>\n",
    "- cabin_staff_service: <sentiment>\n",
    "- food_and_beverages: <sentiment>\n",
    "- inflight_entertainment: <sentiment>\n",
    "- ground_service: <sentiment>\n",
    "- wifi_and_connectivity: <sentiment>\n",
    "- value_for_money: <sentiment>\n",
    "\n",
    "Return only in the above format.\n",
    "\n",
    "Review: {review}\n",
    "Output: \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'seat_comfort pred': 'N/A',\n",
       " 'cabin_staff_service pred': 'Negative',\n",
       " 'food_and_beverages pred': 'N/A',\n",
       " 'inflight_entertainment pred': 'N/A',\n",
       " 'ground_service pred': 'Negative',\n",
       " 'wifi_and_connectivity pred': 'N/A',\n",
       " 'value_for_money pred': 'Negative'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = df.review.sample(1).iloc[0]\n",
    "prompt = tag_prompt_template(tmp)\n",
    "output = llm(prompt, GPT3)\n",
    "parse_output(output, categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Understand the Problems\n",
    "- We may wish to understand the problems the customer is facing\n",
    "- We can accomplish that by mining for information where the customer is unhappy\n",
    "- There exist more efficient methods to do this, we have a flexible exploratory tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_extraction_prompt_template = lambda review, category, sentiment: f\"\"\"This customer had a {sentiment} experience regarding {category}.\n",
    "In less than 10 words describe the problem related to {category}.\n",
    "\n",
    "Review:\n",
    "{review}\n",
    "\n",
    "Short Review:\"\"\"\n",
    "\n",
    "problem_summarization_prompt_template = lambda problem_str, sentiment, category: f\"\"\"Here are some statements from customers that visited our airline.\n",
    "Please break down the main themes that summarize what was {sentiment} about their experience with {category}.\n",
    "Provide a bulleted list with approximate counts and order by most important. Produce 10 themes.\n",
    "\n",
    "\n",
    "Problems:\n",
    "{problem_str}\n",
    "\n",
    "Report:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draft_report(df, category, sentiment, sample_size=40):\n",
    "    reviews = df[(df['category'] == category) & (df['sentiment'] == sentiment)].review.sample(sample_size).tolist()\n",
    "    problem_prompts = [problem_extraction_prompt_template(r, category, sentiment) for r in reviews]\n",
    "\n",
    "    problems = [llm(p) for p in tqdm(problem_prompts, desc='Extracting problems')]\n",
    "    problem_str = '\\n'.join(problems)\n",
    "    report_prompt = problem_summarization_prompt_template(problem_str, sentiment, category)\n",
    "    report = llm(report_prompt)\n",
    "    return report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[139], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m report \u001b[39m=\u001b[39m draft_report(df, \u001b[39m'\u001b[39;49m\u001b[39mcabin_staff_service\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mNegative\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[137], line 5\u001b[0m, in \u001b[0;36mdraft_report\u001b[0;34m(df, category, sentiment, sample_size)\u001b[0m\n\u001b[1;32m      2\u001b[0m reviews \u001b[39m=\u001b[39m df[(df[\u001b[39m'\u001b[39m\u001b[39mcategory\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m category) \u001b[39m&\u001b[39m (df[\u001b[39m'\u001b[39m\u001b[39msentiment\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m sentiment)]\u001b[39m.\u001b[39mreview\u001b[39m.\u001b[39msample(sample_size)\u001b[39m.\u001b[39mtolist()\n\u001b[1;32m      3\u001b[0m problem_prompts \u001b[39m=\u001b[39m [problem_extraction_prompt_template(r, category, sentiment) \u001b[39mfor\u001b[39;00m r \u001b[39min\u001b[39;00m reviews]\n\u001b[0;32m----> 5\u001b[0m problems \u001b[39m=\u001b[39m [llm(p) \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m tqdm(problem_prompts, desc\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mExtracting problems\u001b[39m\u001b[39m'\u001b[39m)]\n\u001b[1;32m      6\u001b[0m problem_str \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(problems)\n\u001b[1;32m      7\u001b[0m report_prompt \u001b[39m=\u001b[39m problem_summarization_prompt_template(problem_str, sentiment, category)\n",
      "Cell \u001b[0;32mIn[137], line 5\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      2\u001b[0m reviews \u001b[39m=\u001b[39m df[(df[\u001b[39m'\u001b[39m\u001b[39mcategory\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m category) \u001b[39m&\u001b[39m (df[\u001b[39m'\u001b[39m\u001b[39msentiment\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m sentiment)]\u001b[39m.\u001b[39mreview\u001b[39m.\u001b[39msample(sample_size)\u001b[39m.\u001b[39mtolist()\n\u001b[1;32m      3\u001b[0m problem_prompts \u001b[39m=\u001b[39m [problem_extraction_prompt_template(r, category, sentiment) \u001b[39mfor\u001b[39;00m r \u001b[39min\u001b[39;00m reviews]\n\u001b[0;32m----> 5\u001b[0m problems \u001b[39m=\u001b[39m [llm(p) \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m tqdm(problem_prompts, desc\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mExtracting problems\u001b[39m\u001b[39m'\u001b[39m)]\n\u001b[1;32m      6\u001b[0m problem_str \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(problems)\n\u001b[1;32m      7\u001b[0m report_prompt \u001b[39m=\u001b[39m problem_summarization_prompt_template(problem_str, sentiment, category)\n",
      "Cell \u001b[0;32mIn[135], line 11\u001b[0m, in \u001b[0;36mllm\u001b[0;34m(user_prompt, model, temperature)\u001b[0m\n\u001b[1;32m      8\u001b[0m model_kwargs \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mtemperature\u001b[39m\u001b[39m\"\u001b[39m: temperature}\n\u001b[1;32m      9\u001b[0m user_prompt \u001b[39m=\u001b[39m user_prompt[:\u001b[39m3700\u001b[39m]\n\u001b[0;32m---> 11\u001b[0m chat_completion \u001b[39m=\u001b[39m CLIENT\u001b[39m.\u001b[39;49mchat\u001b[39m.\u001b[39;49mcompletions\u001b[39m.\u001b[39;49mcreate(\n\u001b[1;32m     12\u001b[0m     messages\u001b[39m=\u001b[39;49m[\n\u001b[1;32m     13\u001b[0m         {\n\u001b[1;32m     14\u001b[0m             \u001b[39m\"\u001b[39;49m\u001b[39mrole\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39muser\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     15\u001b[0m             \u001b[39m\"\u001b[39;49m\u001b[39mcontent\u001b[39;49m\u001b[39m\"\u001b[39;49m: user_prompt\n\u001b[1;32m     16\u001b[0m         },\n\u001b[1;32m     17\u001b[0m     ],\n\u001b[1;32m     18\u001b[0m     model\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mmistralai/Mixtral-8x7B-Instruct-v0.1\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     19\u001b[0m     \u001b[39m# model=\"NousResearch/Nous-Hermes-2-Mixtral-8x7B-SFT\",\u001b[39;49;00m\n\u001b[1;32m     20\u001b[0m     \u001b[39m# model='mistralai/Mistral-7B-Instruct-v0.2',\u001b[39;49;00m\n\u001b[1;32m     21\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_kwargs\n\u001b[1;32m     22\u001b[0m )\n\u001b[1;32m     23\u001b[0m output \u001b[39m=\u001b[39m chat_completion\u001b[39m.\u001b[39mchoices[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mmessage\u001b[39m.\u001b[39mcontent\n\u001b[1;32m     24\u001b[0m \u001b[39mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m~/anaconda3/envs/airline/lib/python3.10/site-packages/openai/_utils/_utils.py:271\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    269\u001b[0m             msg \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mMissing required argument: \u001b[39m\u001b[39m{\u001b[39;00mquote(missing[\u001b[39m0\u001b[39m])\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    270\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 271\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/airline/lib/python3.10/site-packages/openai/resources/chat/completions.py:643\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, presence_penalty, response_format, seed, stop, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[39m@required_args\u001b[39m([\u001b[39m\"\u001b[39m\u001b[39mmessages\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m], [\u001b[39m\"\u001b[39m\u001b[39mmessages\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mstream\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m    595\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[1;32m    596\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    641\u001b[0m     timeout: \u001b[39mfloat\u001b[39m \u001b[39m|\u001b[39m httpx\u001b[39m.\u001b[39mTimeout \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m|\u001b[39m NotGiven \u001b[39m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    642\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ChatCompletion \u001b[39m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m--> 643\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_post(\n\u001b[1;32m    644\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39m/chat/completions\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    645\u001b[0m         body\u001b[39m=\u001b[39;49mmaybe_transform(\n\u001b[1;32m    646\u001b[0m             {\n\u001b[1;32m    647\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mmessages\u001b[39;49m\u001b[39m\"\u001b[39;49m: messages,\n\u001b[1;32m    648\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mmodel\u001b[39;49m\u001b[39m\"\u001b[39;49m: model,\n\u001b[1;32m    649\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mfrequency_penalty\u001b[39;49m\u001b[39m\"\u001b[39;49m: frequency_penalty,\n\u001b[1;32m    650\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mfunction_call\u001b[39;49m\u001b[39m\"\u001b[39;49m: function_call,\n\u001b[1;32m    651\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mfunctions\u001b[39;49m\u001b[39m\"\u001b[39;49m: functions,\n\u001b[1;32m    652\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mlogit_bias\u001b[39;49m\u001b[39m\"\u001b[39;49m: logit_bias,\n\u001b[1;32m    653\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mlogprobs\u001b[39;49m\u001b[39m\"\u001b[39;49m: logprobs,\n\u001b[1;32m    654\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mmax_tokens\u001b[39;49m\u001b[39m\"\u001b[39;49m: max_tokens,\n\u001b[1;32m    655\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mn\u001b[39;49m\u001b[39m\"\u001b[39;49m: n,\n\u001b[1;32m    656\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mpresence_penalty\u001b[39;49m\u001b[39m\"\u001b[39;49m: presence_penalty,\n\u001b[1;32m    657\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mresponse_format\u001b[39;49m\u001b[39m\"\u001b[39;49m: response_format,\n\u001b[1;32m    658\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mseed\u001b[39;49m\u001b[39m\"\u001b[39;49m: seed,\n\u001b[1;32m    659\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mstop\u001b[39;49m\u001b[39m\"\u001b[39;49m: stop,\n\u001b[1;32m    660\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mstream\u001b[39;49m\u001b[39m\"\u001b[39;49m: stream,\n\u001b[1;32m    661\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mtemperature\u001b[39;49m\u001b[39m\"\u001b[39;49m: temperature,\n\u001b[1;32m    662\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mtool_choice\u001b[39;49m\u001b[39m\"\u001b[39;49m: tool_choice,\n\u001b[1;32m    663\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mtools\u001b[39;49m\u001b[39m\"\u001b[39;49m: tools,\n\u001b[1;32m    664\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mtop_logprobs\u001b[39;49m\u001b[39m\"\u001b[39;49m: top_logprobs,\n\u001b[1;32m    665\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mtop_p\u001b[39;49m\u001b[39m\"\u001b[39;49m: top_p,\n\u001b[1;32m    666\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39muser\u001b[39;49m\u001b[39m\"\u001b[39;49m: user,\n\u001b[1;32m    667\u001b[0m             },\n\u001b[1;32m    668\u001b[0m             completion_create_params\u001b[39m.\u001b[39;49mCompletionCreateParams,\n\u001b[1;32m    669\u001b[0m         ),\n\u001b[1;32m    670\u001b[0m         options\u001b[39m=\u001b[39;49mmake_request_options(\n\u001b[1;32m    671\u001b[0m             extra_headers\u001b[39m=\u001b[39;49mextra_headers, extra_query\u001b[39m=\u001b[39;49mextra_query, extra_body\u001b[39m=\u001b[39;49mextra_body, timeout\u001b[39m=\u001b[39;49mtimeout\n\u001b[1;32m    672\u001b[0m         ),\n\u001b[1;32m    673\u001b[0m         cast_to\u001b[39m=\u001b[39;49mChatCompletion,\n\u001b[1;32m    674\u001b[0m         stream\u001b[39m=\u001b[39;49mstream \u001b[39mor\u001b[39;49;00m \u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    675\u001b[0m         stream_cls\u001b[39m=\u001b[39;49mStream[ChatCompletionChunk],\n\u001b[1;32m    676\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/airline/lib/python3.10/site-packages/openai/_base_client.py:1112\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpost\u001b[39m(\n\u001b[1;32m   1099\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   1100\u001b[0m     path: \u001b[39mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1107\u001b[0m     stream_cls: \u001b[39mtype\u001b[39m[_StreamT] \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1108\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ResponseT \u001b[39m|\u001b[39m _StreamT:\n\u001b[1;32m   1109\u001b[0m     opts \u001b[39m=\u001b[39m FinalRequestOptions\u001b[39m.\u001b[39mconstruct(\n\u001b[1;32m   1110\u001b[0m         method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpost\u001b[39m\u001b[39m\"\u001b[39m, url\u001b[39m=\u001b[39mpath, json_data\u001b[39m=\u001b[39mbody, files\u001b[39m=\u001b[39mto_httpx_files(files), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions\n\u001b[1;32m   1111\u001b[0m     )\n\u001b[0;32m-> 1112\u001b[0m     \u001b[39mreturn\u001b[39;00m cast(ResponseT, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest(cast_to, opts, stream\u001b[39m=\u001b[39;49mstream, stream_cls\u001b[39m=\u001b[39;49mstream_cls))\n",
      "File \u001b[0;32m~/anaconda3/envs/airline/lib/python3.10/site-packages/openai/_base_client.py:859\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    850\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[1;32m    851\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    852\u001b[0m     cast_to: Type[ResponseT],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    857\u001b[0m     stream_cls: \u001b[39mtype\u001b[39m[_StreamT] \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    858\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ResponseT \u001b[39m|\u001b[39m _StreamT:\n\u001b[0;32m--> 859\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_request(\n\u001b[1;32m    860\u001b[0m         cast_to\u001b[39m=\u001b[39;49mcast_to,\n\u001b[1;32m    861\u001b[0m         options\u001b[39m=\u001b[39;49moptions,\n\u001b[1;32m    862\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    863\u001b[0m         stream_cls\u001b[39m=\u001b[39;49mstream_cls,\n\u001b[1;32m    864\u001b[0m         remaining_retries\u001b[39m=\u001b[39;49mremaining_retries,\n\u001b[1;32m    865\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/airline/lib/python3.10/site-packages/openai/_base_client.py:887\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    884\u001b[0m     kwargs[\u001b[39m\"\u001b[39m\u001b[39mauth\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcustom_auth\n\u001b[1;32m    886\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 887\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_client\u001b[39m.\u001b[39;49msend(\n\u001b[1;32m    888\u001b[0m         request,\n\u001b[1;32m    889\u001b[0m         stream\u001b[39m=\u001b[39;49mstream \u001b[39mor\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_should_stream_response_body(request\u001b[39m=\u001b[39;49mrequest),\n\u001b[1;32m    890\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    891\u001b[0m     )\n\u001b[1;32m    892\u001b[0m \u001b[39mexcept\u001b[39;00m httpx\u001b[39m.\u001b[39mTimeoutException \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m    893\u001b[0m     log\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mEncountered httpx.TimeoutException\u001b[39m\u001b[39m\"\u001b[39m, exc_info\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/airline/lib/python3.10/site-packages/httpx/_client.py:915\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    907\u001b[0m follow_redirects \u001b[39m=\u001b[39m (\n\u001b[1;32m    908\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfollow_redirects\n\u001b[1;32m    909\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(follow_redirects, UseClientDefault)\n\u001b[1;32m    910\u001b[0m     \u001b[39melse\u001b[39;00m follow_redirects\n\u001b[1;32m    911\u001b[0m )\n\u001b[1;32m    913\u001b[0m auth \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m--> 915\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_handling_auth(\n\u001b[1;32m    916\u001b[0m     request,\n\u001b[1;32m    917\u001b[0m     auth\u001b[39m=\u001b[39;49mauth,\n\u001b[1;32m    918\u001b[0m     follow_redirects\u001b[39m=\u001b[39;49mfollow_redirects,\n\u001b[1;32m    919\u001b[0m     history\u001b[39m=\u001b[39;49m[],\n\u001b[1;32m    920\u001b[0m )\n\u001b[1;32m    921\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    922\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m stream:\n",
      "File \u001b[0;32m~/anaconda3/envs/airline/lib/python3.10/site-packages/httpx/_client.py:943\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    940\u001b[0m request \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(auth_flow)\n\u001b[1;32m    942\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 943\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_handling_redirects(\n\u001b[1;32m    944\u001b[0m         request,\n\u001b[1;32m    945\u001b[0m         follow_redirects\u001b[39m=\u001b[39;49mfollow_redirects,\n\u001b[1;32m    946\u001b[0m         history\u001b[39m=\u001b[39;49mhistory,\n\u001b[1;32m    947\u001b[0m     )\n\u001b[1;32m    948\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/airline/lib/python3.10/site-packages/httpx/_client.py:980\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    977\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_event_hooks[\u001b[39m\"\u001b[39m\u001b[39mrequest\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m    978\u001b[0m     hook(request)\n\u001b[0;32m--> 980\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_single_request(request)\n\u001b[1;32m    981\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    982\u001b[0m     \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_event_hooks[\u001b[39m\"\u001b[39m\u001b[39mresponse\u001b[39m\u001b[39m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/anaconda3/envs/airline/lib/python3.10/site-packages/httpx/_client.py:1016\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1011\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1012\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1013\u001b[0m     )\n\u001b[1;32m   1015\u001b[0m \u001b[39mwith\u001b[39;00m request_context(request\u001b[39m=\u001b[39mrequest):\n\u001b[0;32m-> 1016\u001b[0m     response \u001b[39m=\u001b[39m transport\u001b[39m.\u001b[39;49mhandle_request(request)\n\u001b[1;32m   1018\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(response\u001b[39m.\u001b[39mstream, SyncByteStream)\n\u001b[1;32m   1020\u001b[0m response\u001b[39m.\u001b[39mrequest \u001b[39m=\u001b[39m request\n",
      "File \u001b[0;32m~/anaconda3/envs/airline/lib/python3.10/site-packages/httpx/_transports/default.py:231\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    218\u001b[0m req \u001b[39m=\u001b[39m httpcore\u001b[39m.\u001b[39mRequest(\n\u001b[1;32m    219\u001b[0m     method\u001b[39m=\u001b[39mrequest\u001b[39m.\u001b[39mmethod,\n\u001b[1;32m    220\u001b[0m     url\u001b[39m=\u001b[39mhttpcore\u001b[39m.\u001b[39mURL(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    228\u001b[0m     extensions\u001b[39m=\u001b[39mrequest\u001b[39m.\u001b[39mextensions,\n\u001b[1;32m    229\u001b[0m )\n\u001b[1;32m    230\u001b[0m \u001b[39mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 231\u001b[0m     resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_pool\u001b[39m.\u001b[39;49mhandle_request(req)\n\u001b[1;32m    233\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(resp\u001b[39m.\u001b[39mstream, typing\u001b[39m.\u001b[39mIterable)\n\u001b[1;32m    235\u001b[0m \u001b[39mreturn\u001b[39;00m Response(\n\u001b[1;32m    236\u001b[0m     status_code\u001b[39m=\u001b[39mresp\u001b[39m.\u001b[39mstatus,\n\u001b[1;32m    237\u001b[0m     headers\u001b[39m=\u001b[39mresp\u001b[39m.\u001b[39mheaders,\n\u001b[1;32m    238\u001b[0m     stream\u001b[39m=\u001b[39mResponseStream(resp\u001b[39m.\u001b[39mstream),\n\u001b[1;32m    239\u001b[0m     extensions\u001b[39m=\u001b[39mresp\u001b[39m.\u001b[39mextensions,\n\u001b[1;32m    240\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/airline/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py:268\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[39mwith\u001b[39;00m ShieldCancellation():\n\u001b[1;32m    267\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresponse_closed(status)\n\u001b[0;32m--> 268\u001b[0m     \u001b[39mraise\u001b[39;00m exc\n\u001b[1;32m    269\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    270\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/airline/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py:251\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[39mraise\u001b[39;00m exc\n\u001b[1;32m    250\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 251\u001b[0m     response \u001b[39m=\u001b[39m connection\u001b[39m.\u001b[39;49mhandle_request(request)\n\u001b[1;32m    252\u001b[0m \u001b[39mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[1;32m    253\u001b[0m     \u001b[39m# The ConnectionNotAvailable exception is a special case, that\u001b[39;00m\n\u001b[1;32m    254\u001b[0m     \u001b[39m# indicates we need to retry the request on a new connection.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[39m# might end up as an HTTP/2 connection, but which actually ends\u001b[39;00m\n\u001b[1;32m    259\u001b[0m     \u001b[39m# up as HTTP/1.1.\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pool_lock:\n\u001b[1;32m    261\u001b[0m         \u001b[39m# Maintain our position in the request queue, but reset the\u001b[39;00m\n\u001b[1;32m    262\u001b[0m         \u001b[39m# status so that the request becomes queued again.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/airline/lib/python3.10/site-packages/httpcore/_sync/connection.py:103\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_connection\u001b[39m.\u001b[39mis_available():\n\u001b[1;32m    101\u001b[0m         \u001b[39mraise\u001b[39;00m ConnectionNotAvailable()\n\u001b[0;32m--> 103\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_connection\u001b[39m.\u001b[39;49mhandle_request(request)\n",
      "File \u001b[0;32m~/anaconda3/envs/airline/lib/python3.10/site-packages/httpcore/_sync/http11.py:133\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[39mwith\u001b[39;00m Trace(\u001b[39m\"\u001b[39m\u001b[39mresponse_closed\u001b[39m\u001b[39m\"\u001b[39m, logger, request) \u001b[39mas\u001b[39;00m trace:\n\u001b[1;32m    132\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_response_closed()\n\u001b[0;32m--> 133\u001b[0m \u001b[39mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m~/anaconda3/envs/airline/lib/python3.10/site-packages/httpcore/_sync/http11.py:111\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \u001b[39mwith\u001b[39;00m Trace(\n\u001b[1;32m    104\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mreceive_response_headers\u001b[39m\u001b[39m\"\u001b[39m, logger, request, kwargs\n\u001b[1;32m    105\u001b[0m ) \u001b[39mas\u001b[39;00m trace:\n\u001b[1;32m    106\u001b[0m     (\n\u001b[1;32m    107\u001b[0m         http_version,\n\u001b[1;32m    108\u001b[0m         status,\n\u001b[1;32m    109\u001b[0m         reason_phrase,\n\u001b[1;32m    110\u001b[0m         headers,\n\u001b[0;32m--> 111\u001b[0m     ) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_receive_response_headers(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    112\u001b[0m     trace\u001b[39m.\u001b[39mreturn_value \u001b[39m=\u001b[39m (\n\u001b[1;32m    113\u001b[0m         http_version,\n\u001b[1;32m    114\u001b[0m         status,\n\u001b[1;32m    115\u001b[0m         reason_phrase,\n\u001b[1;32m    116\u001b[0m         headers,\n\u001b[1;32m    117\u001b[0m     )\n\u001b[1;32m    119\u001b[0m \u001b[39mreturn\u001b[39;00m Response(\n\u001b[1;32m    120\u001b[0m     status\u001b[39m=\u001b[39mstatus,\n\u001b[1;32m    121\u001b[0m     headers\u001b[39m=\u001b[39mheaders,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    127\u001b[0m     },\n\u001b[1;32m    128\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/airline/lib/python3.10/site-packages/httpcore/_sync/http11.py:176\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    173\u001b[0m timeout \u001b[39m=\u001b[39m timeouts\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mread\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    175\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 176\u001b[0m     event \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_receive_event(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m    177\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(event, h11\u001b[39m.\u001b[39mResponse):\n\u001b[1;32m    178\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/airline/lib/python3.10/site-packages/httpcore/_sync/http11.py:212\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    209\u001b[0m     event \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_h11_state\u001b[39m.\u001b[39mnext_event()\n\u001b[1;32m    211\u001b[0m \u001b[39mif\u001b[39;00m event \u001b[39mis\u001b[39;00m h11\u001b[39m.\u001b[39mNEED_DATA:\n\u001b[0;32m--> 212\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_network_stream\u001b[39m.\u001b[39;49mread(\n\u001b[1;32m    213\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mREAD_NUM_BYTES, timeout\u001b[39m=\u001b[39;49mtimeout\n\u001b[1;32m    214\u001b[0m     )\n\u001b[1;32m    216\u001b[0m     \u001b[39m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[39m#\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[39m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[39m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[1;32m    223\u001b[0m     \u001b[39m# it as a ConnectError.\u001b[39;00m\n\u001b[1;32m    224\u001b[0m     \u001b[39mif\u001b[39;00m data \u001b[39m==\u001b[39m \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_h11_state\u001b[39m.\u001b[39mtheir_state \u001b[39m==\u001b[39m h11\u001b[39m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[0;32m~/anaconda3/envs/airline/lib/python3.10/site-packages/httpcore/_backends/sync.py:126\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[39mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[1;32m    125\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sock\u001b[39m.\u001b[39msettimeout(timeout)\n\u001b[0;32m--> 126\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv(max_bytes)\n",
      "File \u001b[0;32m~/anaconda3/envs/airline/lib/python3.10/ssl.py:1292\u001b[0m, in \u001b[0;36mSSLSocket.recv\u001b[0;34m(self, buflen, flags)\u001b[0m\n\u001b[1;32m   1288\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1289\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1290\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m   1291\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[0;32m-> 1292\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(buflen)\n\u001b[1;32m   1293\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1294\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv(buflen, flags)\n",
      "File \u001b[0;32m~/anaconda3/envs/airline/lib/python3.10/ssl.py:1165\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1163\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m, buffer)\n\u001b[1;32m   1164\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1165\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m)\n\u001b[1;32m   1166\u001b[0m \u001b[39mexcept\u001b[39;00m SSLError \u001b[39mas\u001b[39;00m x:\n\u001b[1;32m   1167\u001b[0m     \u001b[39mif\u001b[39;00m x\u001b[39m.\u001b[39margs[\u001b[39m0\u001b[39m] \u001b[39m==\u001b[39m SSL_ERROR_EOF \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msuppress_ragged_eofs:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "report = draft_report(df, 'cabin_staff_service', 'Negative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Poor customer service and lack of responsibility (5)\n",
      "- Multiple flight delays and poor communication from cabin staff (4)\n",
      "- Uncomfortable seats and lack of amenities (3)\n",
      "- Inattentive and unhelpful cabin crew (3)\n",
      "- Poor communication and delays from cabin staff (3)\n",
      "- Unprofessional and unfriendly cabin crew (3)\n",
      "- Lost luggage, lack of communication, no reimbursement (1)\n",
      "- Rude and dishonest cabin staff regarding bag policy (1)\n",
      "- Poor ground service, lack of assistance for delayed flight (1)\n",
      "- Stressed and unfriendly cabin staff (1)\n"
     ]
    }
   ],
   "source": [
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "airline",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
